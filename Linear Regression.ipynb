{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb80c426-8d4a-4232-b756-ef6350a547a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65d7aa8d-fd66-41c0-864c-cea972cbdcc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_features):\n",
    "    \"\"\"\n",
    "    Initialize parameters for Linear Regression.\n",
    "\n",
    "    Parameters:\n",
    "    n_features (int): Number of input features (columns in X)\n",
    "\n",
    "    Returns:\n",
    "    W (numpy.ndarray): Weight vector of shape (n_features, 1)\n",
    "    b (float): Bias term initialized to 0.0\n",
    "    \"\"\"\n",
    "    # Initialize weight vector (one weight per feature)\n",
    "    # Shape: (n_features, 1)\n",
    "    W = np.random.rand(n_features, 1)\n",
    "\n",
    "    # Initialize bias term (scalar)\n",
    "    b = 0.0\n",
    "\n",
    "    return W, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f26fe174-5701-4ccf-b1e6-c50f194e3e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(W, b, X):\n",
    "    \"\"\"\n",
    "    Generate predictions using linear regression hypothesis.\n",
    "\n",
    "    Parameters:\n",
    "    W (numpy.ndarray): Weight vector of shape (n_features, 1)\n",
    "    b (float): Bias term\n",
    "    X (numpy.ndarray): Feature matrix of shape (m, n_features)\n",
    "\n",
    "    Returns:\n",
    "    y_pred (numpy.ndarray): Predicted values of shape (m, 1)\n",
    "    \"\"\"\n",
    "    # Linear hypothesis: y_hat = XW + b\n",
    "    y_pred = np.dot(X, W) + b\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63ea0121-d114-4a67-82e1-edd8ed13ea08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Mean Squared Error (MSE).\n",
    "\n",
    "    Parameters:\n",
    "    y (numpy.ndarray): Actual values, shape (m, 1) or (m,)\n",
    "    y_pred (numpy.ndarray): Predicted values, shape (m, 1) or (m,)\n",
    "\n",
    "    Returns:\n",
    "    float: Mean squared error\n",
    "    \"\"\"\n",
    "    # Compute squared differences\n",
    "    squared_error = (y - y_pred) ** 2\n",
    "\n",
    "    # Compute mean of squared errors\n",
    "    mse = np.mean(squared_error)\n",
    "\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76165720-d7f0-4f5d-8881-54af67f0225e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Root Mean Squared Error (RMSE).\n",
    "\n",
    "    Parameters:\n",
    "    y (numpy.ndarray): Actual values, shape (m, 1) or (m,)\n",
    "    y_pred (numpy.ndarray): Predicted values, shape (m, 1) or (m,)\n",
    "\n",
    "    Returns:\n",
    "    float: RMSE value\n",
    "    \"\"\"\n",
    "    mse = np.mean((y - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0da28c98-a3cd-4724-b504-e4b2a8a6e970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def r2_score(y, y_pred):\n",
    "    \"\"\"\n",
    "    Compute R-squared (R²) score.\n",
    "\n",
    "    Parameters:\n",
    "    y (numpy.ndarray): Actual values, shape (m, 1) or (m,)\n",
    "    y_pred (numpy.ndarray): Predicted values, shape (m, 1) or (m,)\n",
    "\n",
    "    Returns:\n",
    "    float: R² score\n",
    "    \"\"\"\n",
    "    ss_res = np.sum((y - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce7e102-ec15-4595-a5ee-aebdec3de61b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(y, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate regression model performance.\n",
    "\n",
    "    Returns:\n",
    "    dict: RMSE and R² scores\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"RMSE\": root_mean_squared_error(y, y_pred),\n",
    "        \"R2\": r2_score(y, y_pred)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e2dc6b2-89bb-4fd9-bfa6-ea0afee238ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_gradients(X, y, y_pred):\n",
    "    \"\"\"\n",
    "    Compute gradients of the loss function with respect to\n",
    "    weights and bias for Linear Regression.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix of shape (m, n_features)\n",
    "    y (numpy.ndarray): Actual target values of shape (m, 1)\n",
    "    y_pred (numpy.ndarray): Predicted values of shape (m, 1)\n",
    "\n",
    "    Returns:\n",
    "    dW (numpy.ndarray): Gradient w.r.t weights, shape (n_features, 1)\n",
    "    db (float): Gradient w.r.t bias\n",
    "    \"\"\"\n",
    "    # Number of training examples\n",
    "    m = X.shape[0]\n",
    "\n",
    "    # Error term (y_pred - y)\n",
    "    error = y_pred - y\n",
    "\n",
    "    # Gradient with respect to weights\n",
    "    dW = (2 / m) * np.dot(X.T, error)\n",
    "\n",
    "    # Gradient with respect to bias\n",
    "    db = (2 / m) * np.sum(error)\n",
    "\n",
    "    return dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "064e617a-da47-42f4-82f7-473d8fa7d490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def update_parameters(W, b, dW, db, learning_rate):\n",
    "    \"\"\"\n",
    "    Update weights and bias using gradient descent.\n",
    "\n",
    "    Parameters:\n",
    "    W (numpy.ndarray): Current weights, shape (n_features, 1)\n",
    "    b (float): Current bias\n",
    "    dW (numpy.ndarray): Gradient w.r.t weights, shape (n_features, 1)\n",
    "    db (float): Gradient w.r.t bias\n",
    "    learning_rate (float): Step size for gradient descent\n",
    "\n",
    "    Returns:\n",
    "    W (numpy.ndarray): Updated weights\n",
    "    b (float): Updated bias\n",
    "    \"\"\"\n",
    "    # Update weights\n",
    "    W = W - learning_rate * dW\n",
    "\n",
    "    # Update bias\n",
    "    b = b - learning_rate * db\n",
    "\n",
    "    return W, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71994760-3b6c-4caa-a900-84bdaa1a64f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, learning_rate, epochs):\n",
    "    \"\"\"\n",
    "    Train Linear Regression model using Gradient Descent.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix of shape (m, n_features)\n",
    "    y (numpy.ndarray): Target values of shape (m, 1)\n",
    "    learning_rate (float): Learning rate for gradient descent\n",
    "    epochs (int): Number of training iterations\n",
    "\n",
    "    Returns:\n",
    "    W (numpy.ndarray): Trained weights of shape (n_features, 1)\n",
    "    b (float): Trained bias\n",
    "    loss_history (list): MSE loss value at each epoch\n",
    "    \"\"\"\n",
    "    # Initialize parameters\n",
    "    n_features = X.shape[1]\n",
    "    W, b = initialize_parameters(n_features)\n",
    "\n",
    "    loss_history = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Step 1: Prediction\n",
    "        y_pred = predict(W, b, X)\n",
    "\n",
    "        # Step 2: Compute loss\n",
    "        loss = mean_squared_error(y, y_pred)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        # Step 3: Compute gradients\n",
    "        dW, db = compute_gradients(X, y, y_pred)\n",
    "\n",
    "        # Step 4: Update parameters\n",
    "        W, b = update_parameters(W, b, dW, db, learning_rate)\n",
    "\n",
    "    return W, b, loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f45bb09e-6b05-4365-8724-a9de92653b9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def linear_regression_train(X, y, learning_rate=0.01, epochs=1000):\n",
    "    \"\"\"\n",
    "    Train a Linear Regression model using Gradient Descent.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix of shape (m, n_features)\n",
    "    y (numpy.ndarray): Target values of shape (m, 1)\n",
    "    learning_rate (float): Learning rate for gradient descent\n",
    "    epochs (int): Number of training iterations\n",
    "\n",
    "    Returns:\n",
    "    model (dict): Trained model containing weights, bias, and loss history\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if X.shape[0] != y.shape[0]:\n",
    "        raise ValueError(\"Number of samples in X and y must match\")\n",
    "\n",
    "    # Train model using gradient descent\n",
    "    W, b, loss_history = gradient_descent(X, y, learning_rate, epochs)\n",
    "\n",
    "    # Package trained model\n",
    "    model = {\n",
    "        \"weights\": W,\n",
    "        \"bias\": b,\n",
    "        \"loss_history\": loss_history\n",
    "    }\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "573e6ef2-5d31-4817-87f7-3bbf48b235bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def linear_regression_predict(X, model):\n",
    "    \"\"\"\n",
    "    Generate predictions using a trained Linear Regression model.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix of shape (m, n_features)\n",
    "    model (dict): Trained model returned by linear_regression_train()\n",
    "\n",
    "    Returns:\n",
    "    y_pred (numpy.ndarray): Predicted values of shape (m, 1)\n",
    "    \"\"\"\n",
    "    # Extract trained parameters\n",
    "    W = model[\"weights\"]\n",
    "    b = model[\"bias\"]\n",
    "\n",
    "    # Generate predictions\n",
    "    y_pred = predict(W, b, X)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18111a4e-fd03-45c1-a078-7ac7d5817986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create dummy data\n",
    "X = np.array([[1],\n",
    "              [2],\n",
    "              [3],\n",
    "              [4],\n",
    "              [5]])\n",
    "\n",
    "y = np.array([[5],\n",
    "              [7],\n",
    "              [9],\n",
    "              [11],\n",
    "              [13]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53d67d5f-d312-4196-b09c-c74cbc9e27a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(X.shape)  # (5, 1)\n",
    "print(y.shape)  # (5, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab70eda8-ab85-44ad-af47-bad59bd1c824",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = linear_regression_train(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    learning_rate=0.01,\n",
    "    epochs=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e37dcaa6-e971-4abc-82a8-30b2ed5c5da6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Learned Weights:\", model[\"weights\"])\n",
    "print(\"Learned Bias:\", model[\"bias\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aee6db3-f3f7-41aa-86a6-b066e7dceb7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Initial Loss:\", model[\"loss_history\"][0])\n",
    "print(\"Final Loss:\", model[\"loss_history\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "000456fd-10eb-4509-87bc-5395e32bf6e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Feature matrix (m=5, n=2)\n",
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [2, 1],\n",
    "    [3, 4],\n",
    "    [4, 3],\n",
    "    [5, 6]\n",
    "])\n",
    "\n",
    "# Target variable\n",
    "y = np.array([\n",
    "    [13],  # 2*1 + 3*2 + 5\n",
    "    [12],  # 2*2 + 3*1 + 5\n",
    "    [23],  # 2*3 + 3*4 + 5\n",
    "    [22],  # 2*4 + 3*3 + 5\n",
    "    [33]   # 2*5 + 3*6 + 5\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0589fb4a-c3d7-438e-99e5-d676b5486ebe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = linear_regression_train(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    learning_rate=0.01,\n",
    "    epochs=2000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "529bb8c9-c995-4215-9544-971cd0ec820d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Weights:\\n\", model[\"weights\"])\n",
    "print(\"Bias:\\n\", model[\"bias\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "076791b0-9e4f-4afc-829c-f6419c6612fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred = linear_regression_predict(X, model)\n",
    "\n",
    "print(\"Predicted:\\n\", y_pred)\n",
    "print(\"Actual:\\n\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53515211-cf11-4ddb-9ca4-d4be5a2f44f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics = evaluate_model(y, y_pred)\n",
    "print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Linear Regression",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
